Aqui está a divisão do código em partes, com uma explicação resumida para cada bloco:


---

1. Importações

import torch
from torch import nn

torch: A biblioteca PyTorch é usada para cálculos com tensores e para construir modelos de aprendizado profundo.

nn: O submódulo de PyTorch usado para construir camadas de redes neurais.



---

2. Classe Module

class Module(nn.Module):
    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)

Uma classe base que herda de nn.Module, o que é comum para todas as camadas em PyTorch.

Ela usa super() para inicializar o comportamento do módulo padrão.



---

3. Classe SelfAttention

class SelfAttention(Module):
    def __init__(self, embed_size, heads):
        super(SelfAttention, self).__init__()
        self.embed_size = embed_size
        self.heads = heads
        self.head_dim = embed_size // heads
        assert self.head_dim * heads == embed_size, "Embed size needs to be divisible by heads"
        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)
        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)
        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)
        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)

Self-Attention: Implementa o mecanismo de atenção, onde entradas são processadas com valores, chaves e consultas para calcular pesos de atenção.

Cabeças de atenção: Divide o embedding em múltiplas partes (heads) para facilitar o processamento paralelo.

Camadas lineares: São aplicadas para calcular as chaves, valores e consultas.



---

4. Método forward em SelfAttention

def forward(self, values, keys, query, mask):
        N = query.shape[0]
        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]
        values = values.reshape(N, value_len, self.heads, self.head_dim)
        keys = keys.reshape(N, key_len, self.heads, self.head_dim)
        queries = query.reshape(N, query_len, self.heads, self.head_dim)
        values = self.values(values)
        keys = self.keys(keys)
        queries = self.queries(queries)
        energy = torch.einsum("nqhd,nkhd->nhqk", [queries, keys])
        
        if mask is not None:
            energy = energy.masked_fill(mask == 0, float('-1e20'))
        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3)
        out = torch.einsum("nhql,nlhd->nqhd", [attention, values]).reshape(N, query_len, self.heads * self.head_dim)
        out = self.fc_out(out)
        return out

Reshape: Reorganiza as entradas para separar o número de cabeças (heads).

Multiplicação de tensores: Usa torch.einsum para calcular a energia entre as consultas e chaves.

Máscara: Se uma máscara é fornecida, ela define certos valores como negativos, ignorando esses cálculos de atenção.

Softmax: Normaliza as pontuações para obter pesos de atenção.

Saída: A atenção é multiplicada pelos valores e depois concatenada em um tensor final, que é processado pela camada final fc_out.



---

5. Classe TransFormerBlock

class TransFormerBlock(Module):
    def __init__(self, embed_size, heads, dropout, forward_expansion):
        super(TransFormerBlock, self).__init__()
        self.attention = SelfAttention(embed_size, heads)
        self.norm1 = nn.LayerNorm(embed_size)
        self.norm2 = nn.LayerNorm(embed_size)
        self.feed_forward = nn.Sequential(
            nn.Linear(embed_size, forward_expansion * embed_size),
            nn.ReLU(),
            nn.Linear(forward_expansion * embed_size, embed_size)
        )
        self.dropout = nn.Dropout(dropout)

Bloco Transformer: Implementa uma camada do Transformer, consistindo de atenção, normalização e um feed-forward network.

Norm: Normaliza as saídas para estabilidade.

Feed-forward: Uma rede neural densa aplicada após a atenção para processamento adicional.



---

6. Classe Encoder

class Encoder(Module):
    def __init__(self, src_vocab_size, embed_size, num_layers, heads, device, forward_expansion, dropout, max_length):
        super(Encoder, self).__init__()
        self.embed_size = embed_size
        self.device = device
        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)
        self.position_embedding = nn.Embedding(max_length, embed_size)
        self.layers = nn.ModuleList([TransFormerBlock(embed_size, heads, dropout, forward_expansion) for _ in range(num_layers)])
        self.dropout = nn.Dropout(dropout)

Codificador (Encoder): Converte as sequências de entrada em embeddings, adiciona informações de posição e aplica várias camadas Transformer.

Embedding: Associa palavras e posições em vetores de alta dimensão.

Camadas: Aplicação repetida de blocos Transformer para maior processamento.



---

7. Classe DecoderBlock

class DecoderBlock(Module):
    def __init__(self, embed_size, heads, forward_expansion, dropout, device):
        super(DecoderBlock, self).__init__()
        self.attention = SelfAttention(embed_size, heads)
        self.norm = nn.LayerNorm(embed_size)
        self.transformer_block = TransFormerBlock(embed_size, heads, dropout, forward_expansion)
        self.dropout = nn.Dropout(dropout)

Bloco Decodificador: Implementa um bloco do decodificador, que também usa a atenção e camadas Transformer para gerar a sequência de saída.



---

8. Classe Decoder

class Decoder(Module):
    def __init__(self, trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length):
        super(Decoder, self).__init__()
        self.device = device
        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)
        self.position_embedding = nn.Embedding(max_length, embed_size)
        self.layers = nn.ModuleList([DecoderBlock(embed_size, heads, forward_expansion, dropout, device) for _ in range(num_layers)])
        self.fc_out = nn.Linear(embed_size, trg_vocab_size)
        self.dropout = nn.Dropout(dropout)

Decodificador: Similar ao Encoder, mas processa a sequência de destino (target) para gerar a saída prevista.

Camada final (fc_out): A saída do decodificador é transformada em previsões de probabilidade para cada palavra no vocabulário.



---

9. Classe Transformer

class Transformer(Module):
    def __init__(self, src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, embed_size=256, num_layers=6, forward_expansion=4, heads=8, dropout=0, device="cpu", max_length=100):
        super(Transformer, self).__init__()
        self.encoder = Encoder(src_vocab_size, embed_size, num_layers, heads, device, forward_expansion, dropout, max_length)
        self.decoder = Decoder(trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length)
        self.src_pad_idx = src_pad_idx
        self.trg_pad_idx = trg_pad_idx
        self.device = device

Modelo Transformer: Junta o codificador (Encoder) e o decodificador (Decoder).

Máscaras de origem e destino: Define máscaras para ignorar os tokens de padding.



---

10. Execução do modelo

if __name__ == "__main__":
    device = torch.device("cpu")
    x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(device)
    trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)
    src_pad_idx = 0
    trg_pad_idx = 0
    src_vocab_size = 10
    trg_vocab_size = 10
    modal = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx).to(device)
    out = modal(x, trg[:, :-1])
    print(out.shape)

Execução: Define os dados de entrada e executa o modelo Transformer, imprimindo a forma da saída.



---

Essa divisão explica cada bloco essencial do código e sua função no modelo Transformer, que é usado em tarefas como tradução automática de idiomas.

